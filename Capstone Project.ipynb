{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import needed libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import xgboost as xgb\n",
    "from time import time\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "sns.set()\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID_code</th>\n",
       "      <th>target</th>\n",
       "      <th>var_0</th>\n",
       "      <th>var_1</th>\n",
       "      <th>var_2</th>\n",
       "      <th>var_3</th>\n",
       "      <th>var_4</th>\n",
       "      <th>var_5</th>\n",
       "      <th>var_6</th>\n",
       "      <th>var_7</th>\n",
       "      <th>...</th>\n",
       "      <th>var_190</th>\n",
       "      <th>var_191</th>\n",
       "      <th>var_192</th>\n",
       "      <th>var_193</th>\n",
       "      <th>var_194</th>\n",
       "      <th>var_195</th>\n",
       "      <th>var_196</th>\n",
       "      <th>var_197</th>\n",
       "      <th>var_198</th>\n",
       "      <th>var_199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.9255</td>\n",
       "      <td>-6.7863</td>\n",
       "      <td>11.9081</td>\n",
       "      <td>5.0930</td>\n",
       "      <td>11.4607</td>\n",
       "      <td>-9.2834</td>\n",
       "      <td>5.1187</td>\n",
       "      <td>18.6266</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4354</td>\n",
       "      <td>3.9642</td>\n",
       "      <td>3.1364</td>\n",
       "      <td>1.6910</td>\n",
       "      <td>18.5227</td>\n",
       "      <td>-2.3978</td>\n",
       "      <td>7.8784</td>\n",
       "      <td>8.5635</td>\n",
       "      <td>12.7803</td>\n",
       "      <td>-1.0914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5006</td>\n",
       "      <td>-4.1473</td>\n",
       "      <td>13.8588</td>\n",
       "      <td>5.3890</td>\n",
       "      <td>12.3622</td>\n",
       "      <td>7.0433</td>\n",
       "      <td>5.6208</td>\n",
       "      <td>16.5338</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6421</td>\n",
       "      <td>7.7214</td>\n",
       "      <td>2.5837</td>\n",
       "      <td>10.9516</td>\n",
       "      <td>15.4305</td>\n",
       "      <td>2.0339</td>\n",
       "      <td>8.1267</td>\n",
       "      <td>8.7889</td>\n",
       "      <td>18.3560</td>\n",
       "      <td>1.9518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6093</td>\n",
       "      <td>-2.7457</td>\n",
       "      <td>12.0805</td>\n",
       "      <td>7.8928</td>\n",
       "      <td>10.5825</td>\n",
       "      <td>-9.0837</td>\n",
       "      <td>6.9427</td>\n",
       "      <td>14.6155</td>\n",
       "      <td>...</td>\n",
       "      <td>2.9057</td>\n",
       "      <td>9.7905</td>\n",
       "      <td>1.6704</td>\n",
       "      <td>1.6858</td>\n",
       "      <td>21.6042</td>\n",
       "      <td>3.1417</td>\n",
       "      <td>-6.5213</td>\n",
       "      <td>8.2675</td>\n",
       "      <td>14.7222</td>\n",
       "      <td>0.3965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0604</td>\n",
       "      <td>-2.1518</td>\n",
       "      <td>8.9522</td>\n",
       "      <td>7.1957</td>\n",
       "      <td>12.5846</td>\n",
       "      <td>-1.8361</td>\n",
       "      <td>5.8428</td>\n",
       "      <td>14.9250</td>\n",
       "      <td>...</td>\n",
       "      <td>4.4666</td>\n",
       "      <td>4.7433</td>\n",
       "      <td>0.7178</td>\n",
       "      <td>1.4214</td>\n",
       "      <td>23.0347</td>\n",
       "      <td>-1.2706</td>\n",
       "      <td>-2.9275</td>\n",
       "      <td>10.2922</td>\n",
       "      <td>17.9697</td>\n",
       "      <td>-8.9996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8369</td>\n",
       "      <td>-1.4834</td>\n",
       "      <td>12.8746</td>\n",
       "      <td>6.6375</td>\n",
       "      <td>12.2772</td>\n",
       "      <td>2.4486</td>\n",
       "      <td>5.9405</td>\n",
       "      <td>19.2514</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.4905</td>\n",
       "      <td>9.5214</td>\n",
       "      <td>-0.1508</td>\n",
       "      <td>9.1942</td>\n",
       "      <td>13.2876</td>\n",
       "      <td>-1.5121</td>\n",
       "      <td>3.9267</td>\n",
       "      <td>9.5031</td>\n",
       "      <td>17.9974</td>\n",
       "      <td>-8.8104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 202 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID_code  target    var_0   var_1    var_2   var_3    var_4   var_5   var_6  \\\n",
       "0  train_0       0   8.9255 -6.7863  11.9081  5.0930  11.4607 -9.2834  5.1187   \n",
       "1  train_1       0  11.5006 -4.1473  13.8588  5.3890  12.3622  7.0433  5.6208   \n",
       "2  train_2       0   8.6093 -2.7457  12.0805  7.8928  10.5825 -9.0837  6.9427   \n",
       "3  train_3       0  11.0604 -2.1518   8.9522  7.1957  12.5846 -1.8361  5.8428   \n",
       "4  train_4       0   9.8369 -1.4834  12.8746  6.6375  12.2772  2.4486  5.9405   \n",
       "\n",
       "     var_7   ...     var_190  var_191  var_192  var_193  var_194  var_195  \\\n",
       "0  18.6266   ...      4.4354   3.9642   3.1364   1.6910  18.5227  -2.3978   \n",
       "1  16.5338   ...      7.6421   7.7214   2.5837  10.9516  15.4305   2.0339   \n",
       "2  14.6155   ...      2.9057   9.7905   1.6704   1.6858  21.6042   3.1417   \n",
       "3  14.9250   ...      4.4666   4.7433   0.7178   1.4214  23.0347  -1.2706   \n",
       "4  19.2514   ...     -1.4905   9.5214  -0.1508   9.1942  13.2876  -1.5121   \n",
       "\n",
       "   var_196  var_197  var_198  var_199  \n",
       "0   7.8784   8.5635  12.7803  -1.0914  \n",
       "1   8.1267   8.7889  18.3560   1.9518  \n",
       "2  -6.5213   8.2675  14.7222   0.3965  \n",
       "3  -2.9275  10.2922  17.9697  -8.9996  \n",
       "4   3.9267   9.5031  17.9974  -8.8104  \n",
       "\n",
       "[5 rows x 202 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of records: 200000\n",
      "Clients that made the transaction: 20098\n",
      "Clients that didn't make the transaction: 179902\n",
      "Percentage of clients that made the transaction: 10.049%\n"
     ]
    }
   ],
   "source": [
    "# Total number of records\n",
    "n_records = len(train)\n",
    "\n",
    "# Number of records where the client made the transaction\n",
    "made = train.target.sum()\n",
    "\n",
    "# Number of records where the client didn't make the transaction\n",
    "didnt_make = n_records - made\n",
    "\n",
    "# Percentage of transaction made\n",
    "percentage = made / n_records * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Total number of records: {}\".format(n_records))\n",
    "print(\"Clients that made the transaction: {}\".format(made))\n",
    "print(\"Clients that didn't make the transaction: {}\".format(didnt_make))\n",
    "print(\"Percentage of clients that made the transaction: {}%\".format(percentage))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#Define the percentage of the dataset to use\n",
    "percent = 1.\n",
    "train_data = train.sample(frac = percent, random_state=0)\n",
    "\n",
    "# Sample records\n",
    "n_records = len(train_data)\n",
    "\n",
    "# Number of records where the client made the transaction\n",
    "made = train_data.target.sum()\n",
    "\n",
    "# Number of records where the client didn't make the transaction\n",
    "didnt_make = n_records - made\n",
    "\n",
    "# Percentage of transaction made\n",
    "percentage = made / n_records * 100\n",
    "\n",
    "# Print the results\n",
    "print(\"Records: {}\".format(n_records))\n",
    "print(\"Clients that made the transaction: {}\".format(made))\n",
    "print(\"Clients that didn't make the transaction: {}\".format(didnt_make))\n",
    "print(\"Percentage of clients that made the transaction: {}%\".format(percentage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Setting up X and y\n",
    "train_data = train.copy()\n",
    "Best_features = ['var_0', 'var_1', 'var_2', 'var_6', 'var_12', 'var_13', 'var_18',\n",
    "       'var_21', 'var_22', 'var_26', 'var_33', 'var_34', 'var_40', 'var_44',\n",
    "       'var_51', 'var_53', 'var_76', 'var_78', 'var_80', 'var_81', 'var_86',\n",
    "       'var_91', 'var_92', 'var_94', 'var_95', 'var_99', 'var_107', 'var_108',\n",
    "       'var_109', 'var_110', 'var_115', 'var_121', 'var_133', 'var_139',\n",
    "       'var_146', 'var_148', 'var_149', 'var_154', 'var_163', 'var_164',\n",
    "       'var_165', 'var_166', 'var_169', 'var_170', 'var_174', 'var_177',\n",
    "       'var_184', 'var_190', 'var_192', 'var_198']\n",
    "y = train_data.target\n",
    "X = train_data.drop(['ID_code', 'target'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X)\n",
    "scaled_features = scaler.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set has 140000 samples.\n",
      "Testing set has 60000 samples.\n"
     ]
    }
   ],
   "source": [
    "# Import train_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the 'features' and 'income' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    test_size = 0.3, \n",
    "                                                    random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print(\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print(\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def train_predict(learner, X_train, y_train, X_test, y_test): \n",
    "    '''\n",
    "    inputs:\n",
    "       - learner: the learning algorithm to be trained and predicted on\n",
    "       - sample_size: the size of samples (number) to be drawn from training set\n",
    "       - X_train: features training set\n",
    "       - y_train: income training set\n",
    "       - X_test: features testing set\n",
    "       - y_test: income testing set\n",
    "    '''\n",
    "    \n",
    "    #results = {}\n",
    "       \n",
    "    #converts data into DMatrix\n",
    "    \n",
    "    D_train = xgb.DMatrix(X_train, label = y_train)\n",
    "    D_test = xgb.DMatrix(X_test, label = y_test)\n",
    "    \n",
    "    # Fit the learner to the training data \n",
    "    learner = learner.fit(X_train, y_train, \n",
    "                          eval_set=[(X_train, y_train)], \n",
    "                          verbose=0,\n",
    "                          early_stopping_rounds=1000)\n",
    "        \n",
    "    # Predictions on the test set(X_test),\n",
    "    predictions_test = learner.predict(X_test)\n",
    "    predictions_train = learner.predict(X_train)\n",
    "\n",
    "    # Roc_auc_score()\n",
    "    #results['auc_train'] = roc_auc_score(y_train, predictions_train)\n",
    "    #results['auc_test'] = roc_auc_score(y_test, predictions_test)\n",
    "    \n",
    "    # Return the results\n",
    "    return roc_auc_score(y_test, predictions_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "results = {}\n",
    "kf = RepeatedKFold(n_splits=2, n_repeats=5, random_state=0)\n",
    "kf.get_n_splits(X)\n",
    "fold = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    clf = XGBClassifier(max_depth=3,\n",
    "                        n_estimators=3000, \n",
    "                        learning_rate=0.05, \n",
    "                        objective='binary:logistic', \n",
    "                        n_jobs=-1)\n",
    "    results[fold] = train_predict(clf, X_train, y_train, X_test, y_test)\n",
    "    print(results[fold])\n",
    "    print()\n",
    "    fold += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "D_train = xgb.DMatrix(X_train, label=y_train)\n",
    "D_test = xgb.DMatrix(X_test, label=y_test)\n",
    "\n",
    "params = {\n",
    "    'objective': \"binary:logistic\", \n",
    "    'colsample_bytree': 0.3, \n",
    "    'learning_rate': 0.1, \n",
    "    'max_depth': 4,\n",
    "    'gamma': 10,\n",
    "    'tree_method': 'hist',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "#cv_results = xgb.cv(dtrain=D_train, params=params, nfold=10,\n",
    "#                    num_boost_round=1000,early_stopping_rounds=50,metrics=\"auc\", as_pandas=True, seed=123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_training(dtrain, params, rounds):\n",
    "    model = xgb.train(dtrain= dtrain, params= params, num_boost_round= rounds)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pred_score(dtest, model):\n",
    "    preds = model.predict(D_test)\n",
    "    return print('The AUC_Score for this model is {}'.format(round(roc_auc_score(y_test, preds), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(data):\n",
    "    data = data.drop(['ID_code'], axis = 1)\n",
    "    scaler = MinMaxScaler() \n",
    "    test_features = scaler.fit_transform(data)\n",
    "    return xgb.DMatrix(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_csv(data):\n",
    "    preds_final = xg_class.predict(data)\n",
    "    predictions = pd.Series(preds_final, index = test['ID_code'], name = 'target')\n",
    "    return predictions.to_csv(\"submission.csv\", header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:33:58] Tree method is selected to be 'hist', which uses a single updater grow_fast_histmaker.\n",
      "The AUC_Score for this model is 0.8913\n"
     ]
    }
   ],
   "source": [
    "model = model_training(D_train, params, 1500)\n",
    "pred_score(D_test, model)\n",
    "test_data = transform_data(test)\n",
    "make_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
